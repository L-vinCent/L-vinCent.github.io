<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta name="google-site-verification" content="m3UI4lcUPqpZrsd0hAa_xv7QZH4x70BTPJzUp-HHnyo" />
<meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />














  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Python," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="这里爬取猫眼电影 TOP100 榜的信息，作为学习的第一个Demo">
<meta name="keywords" content="Python">
<meta property="og:type" content="article">
<meta property="og:title" content="python3 爬虫入门">
<meta property="og:url" content="https://l-vincent.github.io/2017/09/02/python学习/index.html">
<meta property="og:site_name" content="L-vinCent&#39;s Blog">
<meta property="og:description" content="这里爬取猫眼电影 TOP100 榜的信息，作为学习的第一个Demo">
<meta property="og:updated_time" content="2018-04-09T09:04:14.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="python3 爬虫入门">
<meta name="twitter:description" content="这里爬取猫眼电影 TOP100 榜的信息，作为学习的第一个Demo">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://l-vincent.github.io/2017/09/02/python学习/"/>





  <title>python3 爬虫入门 | L-vinCent's Blog</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  















  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">L-vinCent's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">“努力的学习”意味着，要常常去处理那些刚好在你能力极限上的问题</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            目录
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://l-vincent.github.io/2017/09/02/python学习/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan'V">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="L-vinCent's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">python3 爬虫入门</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-09-02T00:00:00+08:00">
                2017-09-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Python/" itemprop="url" rel="index">
                    <span itemprop="name">Python</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/09/02/python学习/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/09/02/python学习/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <hr>
<p>这里爬取猫眼电影 TOP100 榜的信息，作为学习的第一个Demo</p>
<h2 id=""><a href="#" class="headerlink" title=""></a><a id="more"></a></h2><p>有目标才有驱动力</p>
<p>个人觉得python这门语言，入门最好的方式就是直接实战，在做项目的时候去学习，做到每个知识点有的放矢。</p>
<hr>
<p>今天开始接触的python,从爬虫开始。 语言相对来说比较简单，环境配置到是花了不少时间。</p>
<ul>
<li><p>作为新人，建议先选择一个好的开发工具，vim相对来说不是太好用 <a href="https://my.oschina.net/havoc/blog/706852" target="_blank" rel="external"> 10个最好用的python集成开发环境</a></p>
</li>
<li><p>我用的是<a href="https://www.jetbrains.com/pycharm/download/#section=mac" target="_blank" rel="external">pycharm</a>——-<a href="http://idea.lanyus.com" target="_blank" rel="external">注册码这里获取</a></p>
</li>
<li><p><a href="https://www.u3v3.com/ar/1320" target="_blank" rel="external">Mac pycharm环境配置</a></p>
</li>
<li><p><a href="https://www.zhihu.com/question/37787004" target="_blank" rel="external">你有哪些想要分享的 PyCharm 使用技巧</a></p>
</li>
</ul>
<p>有个要注意的点是在引入beautifurSoup库的时候会报错，因为3.x的库需要引入的是beautifurSoup4.</p>
<hr>
<p>到这一步环境配置基本上OK了，可以开始进入正题了</p>
<p>这里我跟的一个教程是<br><a href="https://germey.gitbooks.io/python3webspider/content/1-%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE.html" target="_blank" rel="external">Python3网络爬虫实战</a>，<br>知识点比较广，从一个爬虫事例开始.</p>
<p>###目标<br>提取出猫眼电影 TOP100 榜的电影名称、时间、评分、图片等信息，提取的站点 URL 为：<a href="http://maoyan.com/board/4，提取的结果以文件形式保存下来。" target="_blank" rel="external">http://maoyan.com/board/4，提取的结果以文件形式保存下来。</a></p>
<p>###准备工作<br>添加Requests依赖库,注意不是Request</p>
<p>###抓取分析<br>本节我们需要抓取的目标站点为：<a href="http://maoyan.com/board/4，打开之后便可以查看到榜单的信息，如图" target="_blank" rel="external">http://maoyan.com/board/4，打开之后便可以查看到榜单的信息，如图</a> [盼盼]</p>
<p>网页下滑到最下方可以发现有分页的列表，我们点击一下第二页观察一下页面的URL和内容发生了怎样的变化，如图[盼盼]</p>
<p>可以发现页面的 URL 变成了：<a href="http://maoyan.com/board/4?offset=10" target="_blank" rel="external">http://maoyan.com/board/4?offset=10</a>，相比之前的URL多了一个参数，那就是 offset=10，而目前显示的结果是排行 11-20 名的电影，初步推断这是一个偏移量的参数，再点击下一页，发现页面的 URL 变成了：<a href="http://maoyan.com/board/4?offset=20" target="_blank" rel="external">http://maoyan.com/board/4?offset=20</a>，参数 offset 变成了 20，而显示的结果是排行 21-30 的电影。</p>
<p>由此可以总结出规律，offset 代表了一个偏移量值，如果偏移量为 n，则显示的电影序号就是 n+1 到 n+10，每页显示 10 个。所以如果想获取 TOP100 电影，只需要分开请求 10 次，而 10 次的 offset 参数设置为 0，10，20，…，90 即可，这样获取不同的页面结果之后再用正则表达式提取出相关信息就可以得到 TOP100 的所有电影信息了。</p>
<p>###抓取首页<br>接下来我们用代码实现这个过程，首先抓取第一页的内容，我们实现一个 get_one_page() 方法，传入 url 参数，然后将抓取的页面结果返回，然后再实现一个 main() 方法调用一下，初步代码实现如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">import requests</div><div class="line"></div><div class="line">def get_one_page(url):</div><div class="line">    response = requests.get(url)</div><div class="line">    <span class="keyword">if</span> response.status_code == 200:</div><div class="line">        <span class="built_in">return</span> response.text</div><div class="line">    <span class="built_in">return</span> None</div><div class="line"></div><div class="line">def main():</div><div class="line">    url = <span class="string">'http://maoyan.com/board/4'</span></div><div class="line">    html = get_one_page(url)</div><div class="line">    <span class="built_in">print</span>(html)</div><div class="line"></div><div class="line">main()</div></pre></td></tr></table></figure>
<p>###正则提取<br><a href="http://www.runoob.com/regexp/regexp-syntax.html" target="_blank" rel="external">没接触过正则的看这里</a></p>
<p>接下来网页看一下页面的真实源码[盼盼]</p>
<p>查看其中的一个条目的源代码如图 [盼盼]</p>
<p>可以看到一部电影信息对应的源代码是一个 dd 节点，用正则表达式来提取这里面的一些电影信息，首先需要提取它的排名信息，而它的排名信息是在 class 为 board-index 的 i 节点内，所以所以这里利用非贪婪匹配来提取 i 节点内的信息，正则表达式写为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;</div></pre></td></tr></table></figure>
<p>随后需要提取电影的图片，可以看到在后面有个 a 节点，其内部有两个 img 节点，经过检查后发现第二个 img 节点的 data-src属性是图片的链接，在这里提取第二个 img 节点的 data-src属性，所以正则可以改写如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=<span class="string">"(.*?)"</span></div></pre></td></tr></table></figure>
<p>再往后我们需要提取电影的名称，它在后面的 p 节点内，class 为 name，所以我们可以用 name 做一个标志位，然后进一步提取到其内 a 节点的正文内容，正则改写如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;.*?name.*?a.*?&gt;(.*?)&lt;/a&gt;</div></pre></td></tr></table></figure>
<p>随后如果需要再提取主演、发布时间、评分等内容的话都是同样的原理，最后正则表达式写为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src=&quot;(.*?)&quot;.*?name.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)&lt;/p&gt;.*?integer.*?&gt;(.*?)&lt;/i&gt;.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;</div></pre></td></tr></table></figure>
<p>这样我们一个正则表达式可以匹配一个电影的结果，里面匹配了 7 个信息，接下来我们通过调用 findall() 方法提取出所有的内容，实现一个 parse_one_page() 方法如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">def parse_one_page(html):</div><div class="line">    pattern = re.compile(</div><div class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src="(.*?)".*?name.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)&lt;/p&gt;.*?integer.*?&gt;(.*?)&lt;/i&gt;.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>,</div><div class="line">        re.S)</div><div class="line">    items = re.findall(pattern, html)</div><div class="line">    <span class="built_in">print</span>(items)</div></pre></td></tr></table></figure>
<p>这样我们就可以成功将一页的 10 个电影信息都提取出来,但这样还不够，数据比较杂乱，再将匹配结果处理一下，遍历提取结果并生成字典，方法改写如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line">def parse_one_page(html):</div><div class="line">    pattern = re.compile(</div><div class="line">        <span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(.*?)&lt;/i&gt;.*?data-src="(.*?)".*?name.*?a.*?&gt;(.*?)&lt;/a&gt;.*?star.*?&gt;(.*?)&lt;/p&gt;.*?releasetime.*?&gt;(.*?)&lt;/p&gt;.*?integer.*?&gt;(.*?)&lt;/i&gt;.*?fraction.*?&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>,</div><div class="line">        re.S)</div><div class="line">    items = re.findall(pattern, html)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">        yield &#123;</div><div class="line">            <span class="string">'index'</span>: item[0],</div><div class="line">            <span class="string">'image'</span>: item[1],</div><div class="line">            <span class="string">'title'</span>: item[2].strip(),</div><div class="line">            <span class="string">'actor'</span>: item[3].strip()[3:] <span class="keyword">if</span> len(item[3]) &gt; 3 <span class="keyword">else</span> <span class="string">''</span>,</div><div class="line">            <span class="string">'time'</span>: item[4].strip()[5:] <span class="keyword">if</span> len(item[4]) &gt; 5 <span class="keyword">else</span> <span class="string">''</span>,</div><div class="line">            <span class="string">'score'</span>: item[5].strip() + item[6].strip()</div><div class="line">        &#125;</div></pre></td></tr></table></figure>
<p>这样就可以成功提取出电影的排名、图片、标题、演员、时间、评分内容了，并把它赋值为一个个的字典，形成结构化数据，运行结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">&#123;&apos;image&apos;: &apos;http://p1.meituan.net/movie/20803f59291c47e1e116c11963ce019e68711.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;张国荣,张丰毅,巩俐&apos;, &apos;score&apos;: &apos;9.6&apos;, &apos;index&apos;: &apos;1&apos;, &apos;title&apos;: &apos;霸王别姬&apos;, &apos;time&apos;: &apos;1993-01-01(中国香港)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/__40191813__4767047.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;蒂姆·罗宾斯,摩根·弗里曼,鲍勃·冈顿&apos;, &apos;score&apos;: &apos;9.5&apos;, &apos;index&apos;: &apos;2&apos;, &apos;title&apos;: &apos;肖申克的救赎&apos;, &apos;time&apos;: &apos;1994-10-14(美国)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/fc9d78dd2ce84d20e53b6d1ae2eea4fb1515304.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;让·雷诺,加里·奥德曼,娜塔莉·波特曼&apos;, &apos;score&apos;: &apos;9.5&apos;, &apos;index&apos;: &apos;3&apos;, &apos;title&apos;: &apos;这个杀手不太冷&apos;, &apos;time&apos;: &apos;1994-09-14(法国)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/23/6009725.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;格利高利·派克,奥黛丽·赫本,埃迪·艾伯特&apos;, &apos;score&apos;: &apos;9.1&apos;, &apos;index&apos;: &apos;4&apos;, &apos;title&apos;: &apos;罗马假日&apos;, &apos;time&apos;: &apos;1953-09-02(美国)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/53/1541925.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;汤姆·汉克斯,罗宾·怀特,加里·西尼斯&apos;, &apos;score&apos;: &apos;9.4&apos;, &apos;index&apos;: &apos;5&apos;, &apos;title&apos;: &apos;阿甘正传&apos;, &apos;time&apos;: &apos;1994-07-06(美国)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/11/324629.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;莱昂纳多·迪卡普里奥,凯特·温丝莱特,比利·赞恩&apos;, &apos;score&apos;: &apos;9.5&apos;, &apos;index&apos;: &apos;6&apos;, &apos;title&apos;: &apos;泰坦尼克号&apos;, &apos;time&apos;: &apos;1998-04-03&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/99/678407.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;日高法子,坂本千夏,糸井重里&apos;, &apos;score&apos;: &apos;9.2&apos;, &apos;index&apos;: &apos;7&apos;, &apos;title&apos;: &apos;龙猫&apos;, &apos;time&apos;: &apos;1988-04-16(日本)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/92/8212889.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;马龙·白兰度,阿尔·帕西诺,詹姆斯·凯恩&apos;, &apos;score&apos;: &apos;9.3&apos;, &apos;index&apos;: &apos;8&apos;, &apos;title&apos;: &apos;教父&apos;, &apos;time&apos;: &apos;1972-03-24(美国)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/62/109878.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;周星驰,巩俐,郑佩佩&apos;, &apos;score&apos;: &apos;9.2&apos;, &apos;index&apos;: &apos;9&apos;, &apos;title&apos;: &apos;唐伯虎点秋香&apos;, &apos;time&apos;: &apos;1993-07-01(中国香港)&apos;&#125;</div><div class="line">&#123;&apos;image&apos;: &apos;http://p0.meituan.net/movie/9bf7d7b81001a9cf8adbac5a7cf7d766132425.jpg@160w_220h_1e_1c&apos;, &apos;actor&apos;: &apos;柊瑠美,入野自由,夏木真理&apos;, &apos;score&apos;: &apos;9.3&apos;, &apos;index&apos;: &apos;10&apos;, &apos;title&apos;: &apos;千与千寻&apos;, &apos;time&apos;: &apos;2001-07-20(日本)&apos;&#125;</div></pre></td></tr></table></figure>
<p>到此为止我们就成功提取了单页的电影信息</p>
<h3 id="写入文件"><a href="#写入文件" class="headerlink" title="写入文件"></a>写入文件</h3><p>随后将提取的结果写入文件，在这里直接写入到一个文本文件中，通过 json 库的 dumps() 方法实现字典的序列化，并指定 ensure_ascii 参数为 False，这样可以保证输出的结果是中文形式而不是 Unicode 编码，代码实现如下：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">def write_to_json(content):</div><div class="line">    with open(<span class="string">'result.txt'</span>, <span class="string">'a'</span>) as f:</div><div class="line">        <span class="built_in">print</span>(<span class="built_in">type</span>(json.dumps(content)))</div><div class="line">        f.write(json.dumps(content, ensure_ascii=False,).encode(<span class="string">'utf-8'</span>))</div></pre></td></tr></table></figure>
<p>通过调用 write_to_json() 方法即可实现将字典写入到文本文件的过程，此处的 content 参数就是一部电影的提取结果，是一个字典。</p>
<p>###整合代码<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">def main():</div><div class="line">    url = <span class="string">'http://maoyan.com/board/4'</span></div><div class="line">    html = get_one_page(url)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):</div><div class="line">        write_to_json(item)</div></pre></td></tr></table></figure></p>
<p>###分页爬取<br>遍历一下给这个链接传入一个 offset 参数，实现其他 90 部电影的爬取，添加如下调用即可：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(10):</div><div class="line">        main(offset=i * 10)</div></pre></td></tr></table></figure>
<p>将 main() 方法修改一下，接收一个 offset 值作为偏移量，然后构造 URL 进行爬取，实现如下</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">def main(offset):</div><div class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</div><div class="line">    html = get_one_page(url)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):</div><div class="line">        <span class="built_in">print</span>(item)</div><div class="line">        write_to_file(item)</div></pre></td></tr></table></figure>
<p>###完整代码</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div></pre></td><td class="code"><pre><div class="line">import json</div><div class="line">import requests</div><div class="line">from requests.exceptions import RequestException</div><div class="line">import re</div><div class="line">import time</div><div class="line"></div><div class="line">def get_one_page(url):</div><div class="line">    try:</div><div class="line">        response = requests.get(url)</div><div class="line">        <span class="keyword">if</span> response.status_code == 200:</div><div class="line">            <span class="built_in">return</span> response.text</div><div class="line">        <span class="built_in">return</span> None</div><div class="line">    except RequestException:</div><div class="line">        <span class="built_in">return</span> None</div><div class="line"></div><div class="line">def parse_one_page(html):</div><div class="line">    pattern = re.compile(<span class="string">'&lt;dd&gt;.*?board-index.*?&gt;(\d+)&lt;/i&gt;.*?data-src="(.*?)".*?name"&gt;&lt;a'</span></div><div class="line">                         + <span class="string">'.*?&gt;(.*?)&lt;/a&gt;.*?star"&gt;(.*?)&lt;/p&gt;.*?releasetime"&gt;(.*?)&lt;/p&gt;'</span></div><div class="line">                         + <span class="string">'.*?integer"&gt;(.*?)&lt;/i&gt;.*?fraction"&gt;(.*?)&lt;/i&gt;.*?&lt;/dd&gt;'</span>, re.S)</div><div class="line">    items = re.findall(pattern, html)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> items:</div><div class="line">        yield &#123;</div><div class="line">            <span class="string">'index'</span>: item[0],</div><div class="line">            <span class="string">'image'</span>: item[1],</div><div class="line">            <span class="string">'title'</span>: item[2],</div><div class="line">            <span class="string">'actor'</span>: item[3].strip()[3:],</div><div class="line">            <span class="string">'time'</span>: item[4].strip()[5:],</div><div class="line">            <span class="string">'score'</span>: item[5] + item[6]</div><div class="line">        &#125;</div><div class="line"></div><div class="line">def write_to_file(content):</div><div class="line">    with open(<span class="string">'result.txt'</span>, <span class="string">'a'</span>, encoding=<span class="string">'utf-8'</span>) as f:</div><div class="line">        f.write(json.dumps(content, ensure_ascii=False) + <span class="string">'\n'</span>)</div><div class="line"></div><div class="line">def main(offset):</div><div class="line">    url = <span class="string">'http://maoyan.com/board/4?offset='</span> + str(offset)</div><div class="line">    html = get_one_page(url)</div><div class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> parse_one_page(html):</div><div class="line">        <span class="built_in">print</span>(item)</div><div class="line">        write_to_file(item)</div><div class="line"></div><div class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</div><div class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(10):</div><div class="line">        main(offset=i * 10)</div><div class="line">        time.sleep(1)</div></pre></td></tr></table></figure>
<p>最后 跑起来，能得到一个txt文件，差不多是这样</p>
<hr>
<p>万事开头难，然后中间难，最后也难。</p>
<p>愿每一个程序员都能长命白岁，哈哈</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag"># Python</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/21/Block的实质/" rel="next" title="Block的实质">
                <i class="fa fa-chevron-left"></i> Block的实质
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/12/02/从 map 函数看泛型/" rel="prev" title="从 map 函数看泛型">
                从 map 函数看泛型 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="Pan'V" />
          <p class="site-author-name" itemprop="name">Pan'V</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">43</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">24</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/L-vinCent" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="http://www.jianshu.com/u/4a7b7da390e4" target="_blank" title="简书">
                  
                    <i class="fa fa-fw fa-laptop"></i>
                  
                  简书
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#"><span class="nav-number">1.</span> <span class="nav-text"></span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#写入文件"><span class="nav-number">1.1.</span> <span class="nav-text">写入文件</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
</script>
<div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Pan'V</span>
</div>


<div class="powered-by">
  努力工作,努力生活
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>

<div class="busuanzi-count" >
<span class="site-uv">
<i class="fa fa-user"></i>
<span id="busuanzi_container_site_pv">
访问量: <span id="busuanzi_value_site_pv"></span> 次  
</span>
</span>

<span class="site-pv">
<i class="fa fa-quora"></i>
<span id="busuanzi_container_site_uv">
访客数: <span id="busuanzi_value_site_uv"></span> 人
</span>
</span>
</div>





        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://L-vinCent.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://l-vincent.github.io/2017/09/02/python学习/';
          this.page.identifier = '2017/09/02/python学习/';
          this.page.title = 'python3 爬虫入门';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://L-vinCent.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  





  

  

  

  

  

  

</body>
</html>
